{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 99k params\n",
      "Model has 99k params\n"
     ]
    },
    {
     "ename": "ZeroDivisionError",
     "evalue": "division by zero",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mZeroDivisionError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[20], line 156\u001b[0m\n\u001b[1;32m    153\u001b[0m     model\u001b[39m.\u001b[39mload_state_dict(torch\u001b[39m.\u001b[39mload(PATH))\n\u001b[1;32m    154\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[0;32m--> 156\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m1\u001b[39;49m\u001b[39m/\u001b[39;49m\u001b[39m0\u001b[39;49m)\n\u001b[1;32m    157\u001b[0m train_loss,val_loss \u001b[39m=\u001b[39m estimate_loss()\n\u001b[1;32m    158\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInitial training loss: \u001b[39m\u001b[39m{\u001b[39;00mtrain_loss\u001b[39m}\u001b[39;00m\u001b[39m, val loss: \u001b[39m\u001b[39m{\u001b[39;00mval_loss\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mZeroDivisionError\u001b[0m: division by zero"
     ]
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you thick.\n",
      "\n",
      "Gul\n",
      "They by nothy marows and yourew'tre mus'der of grow of kiver of to havom a a strutus wis hive!\n",
      "\n",
      "Sut gime wan in my the do-was, notr borsher alle furt,\n",
      "Lounier, to of you. Haudsed, dida anon Beasse they sely were the eysird\n",
      "I raiur like\n",
      "trine, Aurcke bear is bealos is varcemp,\n",
      "To sones our rie, not all tehour if a hou?\n",
      "If antireld, in arf. Toud you feal ir a rudvereate in hart to life\n",
      "And sove all bust you wil.\n",
      "\n",
      "Trespen of im, you! is nother uin the in the bein oble,\n",
      "Whou of I MI'll, a is have dedl-dighs procet'stipigh for my oftucte.\n",
      "\n",
      "Haucterlive lenotion cor.\n",
      "\n",
      "MAERD INCI:\n",
      "'Tt, of, I far the wherrieds, all may thy wrar.\n",
      "\n",
      "KING O\n",
      "RINCIO:\n",
      "Alad puccar they thou grung bear pan my I and mere chis bard to fill hich his be chom you love thingly the in thou eake:\n",
      "And antr! Hadere Pre it.\n",
      "\n",
      "MERY RICEO:\n",
      "Yood didan:\n",
      "I kis himen kivensse what wackes! our may in ale!\n",
      "\n",
      "NREO:\n",
      "My st and-deatd, and houbbles wild confiringle vive; die;\n",
      "kniry: lich cawgh I the wich bedragion a be noth we Cadve"
     ]
    }
   ],
   "source": [
    "def generate_text(input: str):\n",
    "    max_tokens = 1000\n",
    "    input_tokens = tokenise(input)\n",
    "    print(input, end='')\n",
    "    \n",
    "    for i in range(max_tokens):\n",
    "        now = model(input_tokens.unsqueeze(0))[0][-1]\n",
    "        now = F.softmax(now, dim= 0)\n",
    "        token = torch.multinomial(now,1).item()\n",
    "        input_tokens = torch.tensor(input_tokens.tolist() + [token])\n",
    "        text = decode([token])\n",
    "        print(text, end='')\n",
    "        input_tokens = input_tokens[-context_length:]\n",
    "                \n",
    "\n",
    "generate_text(\"you\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " whis bens,\n",
      "Whis thirgar tink for and by eee acaing ifs fall andoy thow And wommith to theame?\n",
      "\n",
      "Rome hatheut?\n",
      "\n",
      "BENVO:\n",
      "Mill tak. And Romparn the the dell sor thisild,\n",
      "Heake lus nowell theur, who say anto arier this Waite,\n",
      "And arte the orrest their flor eneque?\n",
      "\n",
      "PRICICK:\n",
      "I you\n",
      "Tord, brees Marred thou ancel.\n",
      "\n",
      "'lance; cas and it misess worsly fis.\n",
      "\n",
      "EDWABES:\n",
      "Nure muel\n",
      "Tooder:\n",
      "I her. Ray kide mall bour gis, ase, and is is us cady--y the hese we younor he it slooks hade to meicke:\n",
      "'botion nut\n",
      "ETarids whath. That she stre homse him,\n",
      "Yo migh creast! liftotord your is hive:\n",
      "I will agarin I as beake; and in you ar poner,\n",
      "But in that and thaul aurt bretle fore I propursed\n",
      "CYodes noth are my as him feal,\n",
      "No wregns, and your thall gend eeford.\n",
      "\n",
      "PAPURIANUS:\n",
      "Whe wo worth\n",
      "So kim you faul the thee but the bing\n",
      "Kirne bee!-Hay forcher's as naye his\n",
      "Whicl say both'd reid bive; and the thickel geet\n",
      "Aw o\n",
      "So mor's the proubstervicarting Buse.\n",
      "\n",
      "Ply axtid ye twill firfaires irvettlal yere;\n",
      "Away, where itrances!\n"
     ]
    }
   ],
   "source": [
    "generate_text(\" \")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3337, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tokenise(\"alik\").unsqueeze(0)\n",
    "output = model(a)\n",
    "F.cross_entropy(output.resize(4,65), F.one_hot(tokenise(\"like\").unsqueeze(0), vocab_size).resize(4, 65).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"models/pavan_gpt_100k_1.91.bin\"\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
