{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model has 1236k params\n",
      "Model has 1236k params\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Transformer:\n\tMissing key(s) in state_dict: \"attention_layes.2.key.weight\", \"attention_layes.2.key.bias\", \"attention_layes.2.query.weight\", \"attention_layes.2.query.bias\", \"attention_layes.2.value.weight\", \"attention_layes.2.value.bias\", \"attention_layes.2.proj.weight\", \"attention_layes.2.proj.bias\", \"attention_layes.3.key.weight\", \"attention_layes.3.key.bias\", \"attention_layes.3.query.weight\", \"attention_layes.3.query.bias\", \"attention_layes.3.value.weight\", \"attention_layes.3.value.bias\", \"attention_layes.3.proj.weight\", \"attention_layes.3.proj.bias\", \"attention_layes.4.key.weight\", \"attention_layes.4.key.bias\", \"attention_layes.4.query.weight\", \"attention_layes.4.query.bias\", \"attention_layes.4.value.weight\", \"attention_layes.4.value.bias\", \"attention_layes.4.proj.weight\", \"attention_layes.4.proj.bias\", \"attention_layes.5.key.weight\", \"attention_layes.5.key.bias\", \"attention_layes.5.query.weight\", \"attention_layes.5.query.bias\", \"attention_layes.5.value.weight\", \"attention_layes.5.value.bias\", \"attention_layes.5.proj.weight\", \"attention_layes.5.proj.bias\", \"mlp_layers.0.layers.2.weight\", \"mlp_layers.0.layers.2.bias\", \"mlp_layers.1.layers.2.weight\", \"mlp_layers.1.layers.2.bias\", \"mlp_layers.2.layers.0.weight\", \"mlp_layers.2.layers.0.bias\", \"mlp_layers.2.layers.2.weight\", \"mlp_layers.2.layers.2.bias\", \"mlp_layers.3.layers.0.weight\", \"mlp_layers.3.layers.0.bias\", \"mlp_layers.3.layers.2.weight\", \"mlp_layers.3.layers.2.bias\", \"mlp_layers.4.layers.0.weight\", \"mlp_layers.4.layers.0.bias\", \"mlp_layers.4.layers.2.weight\", \"mlp_layers.4.layers.2.bias\", \"mlp_layers.5.layers.0.weight\", \"mlp_layers.5.layers.0.bias\", \"mlp_layers.5.layers.2.weight\", \"mlp_layers.5.layers.2.bias\". \n\tUnexpected key(s) in state_dict: \"mlp_layers.0.layers.1.weight\", \"mlp_layers.0.layers.1.bias\", \"mlp_layers.1.layers.1.weight\", \"mlp_layers.1.layers.1.bias\". \n\tsize mismatch for token_embedding.weight: copying a param with shape torch.Size([65, 64]) from checkpoint, the shape in current model is torch.Size([65, 128]).\n\tsize mismatch for pos_embedding.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for attention_layes.0.key.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.0.key.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.0.query.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.0.query.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.0.value.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.0.value.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.0.proj.weight: copying a param with shape torch.Size([64, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.0.proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.1.key.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.1.key.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.1.query.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.1.query.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.1.value.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.1.value.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.1.proj.weight: copying a param with shape torch.Size([64, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.1.proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for mlp_layers.0.layers.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for mlp_layers.0.layers.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for mlp_layers.1.layers.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for mlp_layers.1.layers.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for unembed_layer.weight: copying a param with shape torch.Size([65, 64]) from checkpoint, the shape in current model is torch.Size([65, 128]).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m/Users/pavan/code/scratch/transformer.ipynb Cell 1\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pavan/code/scratch/transformer.ipynb#W0sZmlsZQ%3D%3D?line=153'>154</a>\u001b[0m \u001b[39mif\u001b[39;00m LOAD_MODEL:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pavan/code/scratch/transformer.ipynb#W0sZmlsZQ%3D%3D?line=154'>155</a>\u001b[0m     model \u001b[39m=\u001b[39m Transformer()\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/pavan/code/scratch/transformer.ipynb#W0sZmlsZQ%3D%3D?line=155'>156</a>\u001b[0m     model\u001b[39m.\u001b[39;49mload_state_dict(torch\u001b[39m.\u001b[39;49mload(PATH))\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pavan/code/scratch/transformer.ipynb#W0sZmlsZQ%3D%3D?line=156'>157</a>\u001b[0m     model\u001b[39m.\u001b[39meval()\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/pavan/code/scratch/transformer.ipynb#W0sZmlsZQ%3D%3D?line=158'>159</a>\u001b[0m train_loss,val_loss \u001b[39m=\u001b[39m estimate_loss()\n",
      "File \u001b[0;32m~/Library/Python/3.9/lib/python/site-packages/torch/nn/modules/module.py:1671\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m   1666\u001b[0m         error_msgs\u001b[39m.\u001b[39minsert(\n\u001b[1;32m   1667\u001b[0m             \u001b[39m0\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mMissing key(s) in state_dict: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m. \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1668\u001b[0m                 \u001b[39m'\u001b[39m\u001b[39m, \u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(\u001b[39m'\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(k) \u001b[39mfor\u001b[39;00m k \u001b[39min\u001b[39;00m missing_keys)))\n\u001b[1;32m   1670\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(error_msgs) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m-> 1671\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\u001b[39m'\u001b[39m\u001b[39mError(s) in loading state_dict for \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m{}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[1;32m   1672\u001b[0m                        \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\\t\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   1673\u001b[0m \u001b[39mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Transformer:\n\tMissing key(s) in state_dict: \"attention_layes.2.key.weight\", \"attention_layes.2.key.bias\", \"attention_layes.2.query.weight\", \"attention_layes.2.query.bias\", \"attention_layes.2.value.weight\", \"attention_layes.2.value.bias\", \"attention_layes.2.proj.weight\", \"attention_layes.2.proj.bias\", \"attention_layes.3.key.weight\", \"attention_layes.3.key.bias\", \"attention_layes.3.query.weight\", \"attention_layes.3.query.bias\", \"attention_layes.3.value.weight\", \"attention_layes.3.value.bias\", \"attention_layes.3.proj.weight\", \"attention_layes.3.proj.bias\", \"attention_layes.4.key.weight\", \"attention_layes.4.key.bias\", \"attention_layes.4.query.weight\", \"attention_layes.4.query.bias\", \"attention_layes.4.value.weight\", \"attention_layes.4.value.bias\", \"attention_layes.4.proj.weight\", \"attention_layes.4.proj.bias\", \"attention_layes.5.key.weight\", \"attention_layes.5.key.bias\", \"attention_layes.5.query.weight\", \"attention_layes.5.query.bias\", \"attention_layes.5.value.weight\", \"attention_layes.5.value.bias\", \"attention_layes.5.proj.weight\", \"attention_layes.5.proj.bias\", \"mlp_layers.0.layers.2.weight\", \"mlp_layers.0.layers.2.bias\", \"mlp_layers.1.layers.2.weight\", \"mlp_layers.1.layers.2.bias\", \"mlp_layers.2.layers.0.weight\", \"mlp_layers.2.layers.0.bias\", \"mlp_layers.2.layers.2.weight\", \"mlp_layers.2.layers.2.bias\", \"mlp_layers.3.layers.0.weight\", \"mlp_layers.3.layers.0.bias\", \"mlp_layers.3.layers.2.weight\", \"mlp_layers.3.layers.2.bias\", \"mlp_layers.4.layers.0.weight\", \"mlp_layers.4.layers.0.bias\", \"mlp_layers.4.layers.2.weight\", \"mlp_layers.4.layers.2.bias\", \"mlp_layers.5.layers.0.weight\", \"mlp_layers.5.layers.0.bias\", \"mlp_layers.5.layers.2.weight\", \"mlp_layers.5.layers.2.bias\". \n\tUnexpected key(s) in state_dict: \"mlp_layers.0.layers.1.weight\", \"mlp_layers.0.layers.1.bias\", \"mlp_layers.1.layers.1.weight\", \"mlp_layers.1.layers.1.bias\". \n\tsize mismatch for token_embedding.weight: copying a param with shape torch.Size([65, 64]) from checkpoint, the shape in current model is torch.Size([65, 128]).\n\tsize mismatch for pos_embedding.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([256, 128]).\n\tsize mismatch for attention_layes.0.key.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.0.key.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.0.query.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.0.query.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.0.value.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.0.value.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.0.proj.weight: copying a param with shape torch.Size([64, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.0.proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.1.key.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.1.key.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.1.query.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.1.query.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.1.value.weight: copying a param with shape torch.Size([16, 64]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.1.value.bias: copying a param with shape torch.Size([16]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for attention_layes.1.proj.weight: copying a param with shape torch.Size([64, 16]) from checkpoint, the shape in current model is torch.Size([128, 128]).\n\tsize mismatch for attention_layes.1.proj.bias: copying a param with shape torch.Size([64]) from checkpoint, the shape in current model is torch.Size([128]).\n\tsize mismatch for mlp_layers.0.layers.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for mlp_layers.0.layers.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for mlp_layers.1.layers.0.weight: copying a param with shape torch.Size([256, 64]) from checkpoint, the shape in current model is torch.Size([512, 128]).\n\tsize mismatch for mlp_layers.1.layers.0.bias: copying a param with shape torch.Size([256]) from checkpoint, the shape in current model is torch.Size([512]).\n\tsize mismatch for unembed_layer.weight: copying a param with shape torch.Size([65, 64]) from checkpoint, the shape in current model is torch.Size([65, 128])."
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from matplotlib import pyplot as plt\n",
    "import time\n",
    "import random\n",
    "import math\n",
    "PATH = \"models/pavan_gpt_100k_1.91.bin\"\n",
    "LOAD_MODEL = False\n",
    "\n",
    "\n",
    "torch.manual_seed(1)\n",
    "\n",
    "inf = torch.inf\n",
    "context_length = 256 # No of tokens\n",
    "model_dim = 128 # dimension of the model -> residual stream\n",
    "n_layers = 6 # no of layers\n",
    "n_heads = 0 # No of attention heads for layer # TODO\n",
    "head_dim = 128\n",
    "vocab_size = 65\n",
    "learning_rate = 3e-4\n",
    "max_iters = 5000\n",
    "eval_iters = 100\n",
    "batch_size = 32 #Takes 27k iters\n",
    "\n",
    "lower_triangular_matrix = torch.tensor([[1 if i<=j else -torch.inf for i in range(context_length)] for j in range(context_length)]).float()\n",
    "\n",
    "def tokenise(str: str):\n",
    "    return torch.tensor([char_map[i] for i in str])\n",
    "\n",
    "def decode(tokens: list[str]):\n",
    "    return ''.join([reverse_char_map[i] for i in tokens])\n",
    "\n",
    "file = open(\"tiny_shakesphere.txt\", \"r\")\n",
    "full_data = file.read()\n",
    "\n",
    "vocab = list(sorted((set(full_data))))\n",
    "\n",
    "char_map = {vocab[i]: i for i in range(len(vocab))}\n",
    "reverse_char_map = {char_map[i] : i for i in char_map}\n",
    "full_data = tokenise(full_data)\n",
    "\n",
    "total_datapoints  = full_data.shape[0]\n",
    "\n",
    "training_data : list[int] = full_data[:int(total_datapoints*0.9)]\n",
    "validation_data = full_data[int(total_datapoints*0.9):total_datapoints]\n",
    "\n",
    "\n",
    "def sample_data(split: str = \"train\"): # With replacement\n",
    "    data = training_data if split == 'train' else validation_data\n",
    "    ix = torch.randint(len(data) - context_length, (batch_size,))\n",
    "    x = torch.stack([data[i:i+context_length] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+context_length+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "@torch.no_grad()\n",
    "def estimate_loss():\n",
    "    out = {}\n",
    "    model.eval()\n",
    "    for split in ['train', 'val']:\n",
    "        losses = torch.zeros(eval_iters)\n",
    "        for k in range(eval_iters):\n",
    "            X, Y = sample_data(split)\n",
    "            _, loss = model(X, Y)\n",
    "            losses[k] = loss.item()\n",
    "        out[split] = losses.mean()\n",
    "    model.train()\n",
    "    \n",
    "    return out[\"train\"], out['val']\n",
    "\n",
    "\n",
    "class Layer(nn.Module):\n",
    "    def __init__(self) -> None:\n",
    "        super().__init__()\n",
    "        \n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.key = nn.Linear(model_dim, head_dim)\n",
    "        self.query = nn.Linear(model_dim, head_dim)\n",
    "        self.value = nn.Linear(model_dim, head_dim)\n",
    "        self.proj = nn.Linear(head_dim, model_dim)\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, idx):\n",
    "        key = self.key(idx) # (batch, context_length, head_dim)\n",
    "        query = self.query(idx)\n",
    "        value = self.value(idx) # (batch, context_length, head_dim)\n",
    "\n",
    "        attention = (query@torch.transpose(key,1,2))/(math.sqrt(head_dim)) # (batch, context_length, context_length)\n",
    "\n",
    "        attention = torch.tril(attention)\n",
    "\n",
    "        attention = attention.masked_fill(attention == 0, -inf)\n",
    "\n",
    "        attention = F.softmax(attention,-1) # probs along context_length sum to 1\n",
    "\n",
    "        attention_value = attention@value  # (batch, context_length, head_dim)\n",
    "\n",
    "        attention_value = self.proj(attention_value)  # (batch, context_length, model_dim)\n",
    "        return self.dropout(attention_value)\n",
    "    \n",
    "\n",
    "class MLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layers = nn.Sequential(nn.Linear(model_dim, 4*model_dim), nn.ReLU(), nn.Linear(4*model_dim, model_dim))\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "    \n",
    "    def forward(self, idx):\n",
    "        logits = self.layers(idx)\n",
    "        return self.dropout(logits)\n",
    "\n",
    "class Transformer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.token_embedding = nn.Embedding(vocab_size, model_dim)\n",
    "        self.pos_embedding = nn.Embedding(context_length, model_dim)\n",
    "        self.attention_layes = nn.ModuleList([AttentionHead() for i in range(n_layers)])\n",
    "        self.mlp_layers = nn.ModuleList([MLP() for i in range(n_layers)])\n",
    "        self.unembed_layer = nn.Linear(model_dim,vocab_size)\n",
    "\n",
    "        self.total_parameters = sum([p.numel() for p in self.parameters()])\n",
    "        print(f\"Model has {self.total_parameters//1000}k params\")\n",
    "\n",
    "\n",
    "    def forward(self, idx, targets = None):\n",
    "        # idx -> [1,2,0,3..] (batch, context_length)\n",
    "\n",
    "        # for p in range(idx.shape[0]):\n",
    "        #     print([decode(idx[p].tolist()), decode(targets[p].tolist())])\n",
    "\n",
    "        input_sequence_length = idx.shape[-1]\n",
    "\n",
    "        residual_stream = self.token_embedding(idx)  # (batch, context_length, model_dim)\n",
    "        residual_stream = residual_stream + self.pos_embedding(torch.tensor([i for i in range(input_sequence_length)])) # Pos embedding will be # (context_length, model_dim)\n",
    "        \n",
    "        for i in range(n_layers):\n",
    "            residual_stream = residual_stream + self.attention_layes[i](residual_stream)\n",
    "            residual_stream = residual_stream + self.mlp_layers[i](residual_stream)\n",
    "\n",
    "        residual_stream = self.unembed_layer(residual_stream) # (batch, context_length, vocab_size)\n",
    "        if targets is None:\n",
    "            return residual_stream\n",
    "        (x,y,z) = residual_stream.shape\n",
    "        loss = F.cross_entropy(residual_stream.view(x*y,z), targets.view(x*y))\n",
    "        return residual_stream, loss\n",
    "    \n",
    "\n",
    "model = Transformer()\n",
    "\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    model = Transformer()\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.eval()\n",
    "\n",
    "train_loss,val_loss = estimate_loss()\n",
    "print(f\"Initial training loss: {train_loss}, val loss: {val_loss}\")\n",
    "\n",
    "loss_value = []\n",
    "val_loss_value = []\n",
    "iters = []\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = learning_rate)\n",
    "step_value = max_iters/20\n",
    "start_time = time.time()\n",
    "for iter in range(max_iters):\n",
    "    X,Y= sample_data() # (B, context_length)\n",
    "    logits, loss = model(X, Y)  # (B, context_length, vocab_size)\n",
    "    if iter%step_value ==0:\n",
    "        train_loss,val_loss = estimate_loss()\n",
    "        iters.append(iter)\n",
    "        loss_value.append(train_loss)\n",
    "        val_loss_value.append(val_loss)\n",
    "        print(f\"iter:{iter} training loss: {train_loss}, val loss: {val_loss}\")\n",
    "\n",
    "    \n",
    "    optimizer.zero_grad(set_to_none=True)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    \n",
    "end_time = time.time()\n",
    "print(f\"Took {end_time-start_time}s for {max_iters} epochs\")\n",
    "\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.plot(iters,loss_value, color='blue', label=\"Training\")\n",
    "plt.plot(iters, val_loss_value, \"red\", label = \"validation\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "your lord;\n",
      "From your from my faulters.\n",
      "\n",
      "herredness on my and bears:\n",
      "Bell though trel'd topil'd cortain not swould or\n",
      "Littleman tor lass of the strongs hone;\n",
      "Now and answer.\n",
      "\n",
      "First Secondier: well, by crabelandamp'd you not? forse?\n",
      "\n",
      "Epioram,\n",
      "God bell, the alse your which obth'ts you,\n",
      "More for his comforthersomenly die,\n",
      "Cought mother or it, Bukchil'd he grosery?'\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "No. I, to not you be many.\n",
      "\n",
      "POMPEY:\n",
      "Go, homon is be Coase have you cbare,\n",
      "Or led, true and edgrille, my orrackly to age,\n",
      "Werel twhen not say, not to hour flitter'd gary\n",
      "Thou lie From For\n",
      "chento worse chride pherinon\n",
      "Is thee of a' thine: he chountie! Speet to ie at are our than and reclorine,\n",
      "Andwelcome have plectate.'\n",
      "Chown, palys tekunctio, my indid,\n",
      "Why sidon flow, of honds with that\n",
      "Lord himself; and be his ear the Ciriall:\n",
      "Go this must sir?\n",
      "\n",
      "GAUCESSTUS:\n",
      "Then thee; and crovedles tence hate,\n",
      "And seech them, this know\n",
      "za, sir, sagancinmon'd tend, till ques.\n",
      "\n",
      "DUKE VINCENTIO:\n",
      "Low not not and evilt her,\n",
      "I'll ats in t"
     ]
    }
   ],
   "source": [
    "def generate_text(input: str):\n",
    "    max_tokens = 1000\n",
    "    input_tokens = tokenise(input)\n",
    "    print(input, end='')\n",
    "    \n",
    "    for i in range(max_tokens):\n",
    "        now = model(input_tokens.unsqueeze(0))[0][-1]\n",
    "        now = F.softmax(now, dim= 0)\n",
    "        token = torch.multinomial(now,1).item()\n",
    "        input_tokens = torch.tensor(input_tokens.tolist() + [token])\n",
    "        text = decode([token])\n",
    "        print(text, end='')\n",
    "        input_tokens = input_tokens[-context_length:]\n",
    "                \n",
    "\n",
    "generate_text(\"you\")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " whis bens,\n",
      "Whis thirgar tink for and by eee acaing ifs fall andoy thow And wommith to theame?\n",
      "\n",
      "Rome hatheut?\n",
      "\n",
      "BENVO:\n",
      "Mill tak. And Romparn the the dell sor thisild,\n",
      "Heake lus nowell theur, who say anto arier this Waite,\n",
      "And arte the orrest their flor eneque?\n",
      "\n",
      "PRICICK:\n",
      "I you\n",
      "Tord, brees Marred thou ancel.\n",
      "\n",
      "'lance; cas and it misess worsly fis.\n",
      "\n",
      "EDWABES:\n",
      "Nure muel\n",
      "Tooder:\n",
      "I her. Ray kide mall bour gis, ase, and is is us cady--y the hese we younor he it slooks hade to meicke:\n",
      "'botion nut\n",
      "ETarids whath. That she stre homse him,\n",
      "Yo migh creast! liftotord your is hive:\n",
      "I will agarin I as beake; and in you ar poner,\n",
      "But in that and thaul aurt bretle fore I propursed\n",
      "CYodes noth are my as him feal,\n",
      "No wregns, and your thall gend eeford.\n",
      "\n",
      "PAPURIANUS:\n",
      "Whe wo worth\n",
      "So kim you faul the thee but the bing\n",
      "Kirne bee!-Hay forcher's as naye his\n",
      "Whicl say both'd reid bive; and the thickel geet\n",
      "Aw o\n",
      "So mor's the proubstervicarting Buse.\n",
      "\n",
      "Ply axtid ye twill firfaires irvettlal yere;\n",
      "Away, where itrances!\n"
     ]
    }
   ],
   "source": [
    "generate_text(\" \")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.3337, grad_fn=<DivBackward1>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tokenise(\"alik\").unsqueeze(0)\n",
    "output = model(a)\n",
    "F.cross_entropy(output.resize(4,65), F.one_hot(tokenise(\"like\").unsqueeze(0), vocab_size).resize(4, 65).float())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = \"models/pavan_gpt_1M_1.48.bin\"\n",
    "torch.save(model.state_dict(), PATH)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
